{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmeAnoI6gNdy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "# Import necessary modules\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yg6OaiyVgNd3"
   },
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    \n",
    "    data = None\n",
    "    def __init__(self,data_dir):\n",
    "            self.data_dir = data_dir\n",
    "    \n",
    "    def preprocess(self,test_size):\n",
    "\n",
    "            #Loading datasets\n",
    "            self.data=pd.read_csv(self.data_dir)\n",
    "\n",
    "            #pre-processing\n",
    "            #self.data.drop('Data point',inplace=True,axis=1)\n",
    "            #self.data.drop('Time (s)',inplace=True,axis=1)\n",
    "\n",
    "            # Removing Empty Records\n",
    "            self.data.dropna(axis=0,how='all',inplace=True)\n",
    "\n",
    "            # Removal of NaN Columns\n",
    "            columns = self.data.columns\n",
    "            nan_columns = list(filter(lambda x:self.data[x].isna().sum()>0.5*len(self.data),columns))\n",
    "            self.data = self.data.drop(nan_columns,axis=1)\n",
    "\n",
    "            # Correlation (Feature Selection)\n",
    "            corr = self.data.corr()\n",
    "            columns = corr.columns\n",
    "            threshold = 0.1 # columns lesser than 0.01 and greater -0.01  not that correlated\n",
    "            less_important_columns = []\n",
    "            \n",
    "            for column in columns:\n",
    "                column_correlation = corr[column]\n",
    "                not_correlated_count = 0\n",
    "                # Checking correlation factor with other columns\n",
    "                for other_column in columns:\n",
    "                    if(column_correlation[other_column]<threshold and column_correlation[other_column]>-threshold):\n",
    "                        # Counting no of columns with which the current column is less correlated\n",
    "                        not_correlated_count+=1\n",
    "              \n",
    "            # Adding to the list if its less correlated with more than 50% of the total columns\n",
    "            if(not_correlated_count>0.5*len(columns)):less_important_columns.append(column)\n",
    "            \n",
    "            self.data = self.data.drop(less_important_columns,axis=1)\n",
    "\n",
    "            # Filling Values\n",
    "            \n",
    "            # lst = ['Feature 1','Label','Feature 4', 'Feature 5','Feature 6','Feature 7','Feature 8','Feature 9','Feature 10','Feature 11','Feature 12']\n",
    "            # for wrd in lst:self.data[wrd]=self.data[wrd].interpolate()\n",
    "            # self.data['Feature 3']=self.data['Feature 3'].ffill()\n",
    "            \n",
    "            # Finding Categorical and Continuous\n",
    "            categorical_columns  = list(filter(lambda x:1.*self.data[x].nunique()/self.data[x].count() < 0.05,self.data.columns))\n",
    "            continuous_columns   = list(set(self.data.columns).difference(set(categorical_columns)))\n",
    "\n",
    "            for col in categorical_columns:self.data[col] = self.data[col].ffill()\n",
    "            for col in continuous_columns:self.data[col] = self.data[col].interpolate()\n",
    "\n",
    "            self.data=self.data.drop(1,axis=0)\n",
    "            self.data=self.data.drop(0,axis=0)\n",
    "            \n",
    "            # Splitting x and y\n",
    "            x=np.array(self.data.iloc[0:,0:11])\n",
    "            y=np.array(self.data.iloc[0:,11])\n",
    "\n",
    "            # data feature scaling\n",
    "            scaler = StandardScaler()\n",
    "            scaler = scaler.fit(x)\n",
    "            x=scaler.transform(x)\n",
    "\n",
    "            #Train test split\n",
    "            X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=test_size,random_state=42)  \n",
    "            \n",
    "            return [X_train,y_train,X_val,y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYpeieJlgNd4"
   },
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    X_train,X_val,X_test1,X_test2 = None,None,None,None\n",
    "    y_train,y_val,y_test1,y_test2 = None,None,None,None\n",
    "\n",
    "    RMSE_TEST1  = {'LINEAR REGRESSION':0,'LINEAR REGRESSION SKLEARN':0,'DECISION TREE':0,'RANDOM FOREST':0,'NEURAL NETWORK':0}\n",
    "    RMSE_TEST2  = {'LINEAR REGRESSION':0,'LINEAR REGRESSION SKLEARN':0,'DECISION TREE':0,'RANDOM FOREST':0,'NEURAL NETWORK':0}\n",
    "\n",
    "    MSE_TEST1  = {'LINEAR REGRESSION':0,'LINEAR REGRESSION SKLEARN':0,'DECISION TREE':0,'RANDOM FOREST':0,'NEURAL NETWORK':0}\n",
    "    MSE_TEST2  = {'LINEAR REGRESSION':0,'LINEAR REGRESSION SKLEARN':0,'DECISION TREE':0,'RANDOM FOREST':0,'NEURAL NETWORK':0}\n",
    "\n",
    "\n",
    "    def __init__(self,X_train,y_train,X_val,y_val,X_test1,y_test1,X_test2,y_test2):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.X_test1 = X_test1\n",
    "        self.X_test2 = X_test2\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.y_test1 = y_test1\n",
    "        self.y_test2 = y_test2\n",
    "\n",
    "    def rmse(self,predictions,target):return sqrt(((predictions-target)**2).mean())\n",
    "\n",
    "    def tabulate(self,options=['all']):\n",
    "        # options = ['LINEAR REGRESSION','LINEAR REGRESSION SKLEARN']\n",
    "        E_TEST_lst = []\n",
    "        if(options[0] == 'all'):E_TEST_lst = [self.RMSE_TEST1,self.RMSE_TEST2,self.MSE_TEST1,self.MSE_TEST2]\n",
    "        else:\n",
    "            rmse_test1 = {}\n",
    "            rmse_test2 = {}\n",
    "            mse_test1 = {}\n",
    "            mse_test2 = {}\n",
    "\n",
    "            lf = list(filter(lambda x:x in self.RMSE_TEST1.keys,options))\n",
    "            if(len(lf)!=len(options)):\n",
    "                print(\"Invalid Options Present\")\n",
    "                return\n",
    "\n",
    "            for option in options:\n",
    "                rmse_test1[option] = self.RMSE_TEST1[option]\n",
    "                rmse_test2[option] = self.RMSE_TEST2[option]\n",
    "                mse_test1[option] = self.MSE_TEST1[option]\n",
    "                mse_test2[option] = self.MSE_TEST2[option]\n",
    "\n",
    "            E_test_lst = [rmse_test1,rmse_test2,mse_test1,mse_test2]\n",
    "\n",
    "        E_TEST_df = pd.DataFrame(E_TEST_lst,index=['TEST1','TEST2'])\n",
    "        display(E_TEST_df)\n",
    "        \n",
    "    def model(self,model_type = 'decision_tree_sklearn'):\n",
    "\n",
    "        if(model_type == 'all'):\n",
    "            self.linear_regression()\n",
    "            self.linear_regression_sklearn()\n",
    "            self.decision_tree_sklearn()\n",
    "            self.random_forest_sklearn()\n",
    "            self.tabulate(['all'])\n",
    "\n",
    "        if(model_type == 'linear_regression'):\n",
    "            self.linear_regression()\n",
    "            self.tabulate(['LINEAR REGRESSION'])\n",
    "\n",
    "        elif(model_type == 'linear_regression_sklearn'):\n",
    "            self.linear_regression_sklearn()\n",
    "            self.tabulate(['LINEAR REGRESSION SKLEARN'])\n",
    "\n",
    "        elif(model_type == 'decision_tree_sklearn'):\n",
    "            self.decision_tree_sklearn()\n",
    "            self.tabulate(['DECISION TREE SKLEARN'])\n",
    "\n",
    "        elif(model_type == 'random_forest_sklearn'):\n",
    "            self.random_forest_sklearn()\n",
    "            self.tabulate(['RANDOM FOREST SKLEARN'])\n",
    "            \n",
    "    def linear_regression(self):\n",
    "        # linear regression code\n",
    "        costs_train=[]\n",
    "        costs_val=[]\n",
    "        cost_list=[]\n",
    "        m=self.X_train.shape[0]\n",
    "        ones= np.ones((m,1))\n",
    "        self.X_train =np.concatenate((ones,self.X_train),axis=1)\n",
    "        self.X_val = np.concatenate((np.ones((self.X_val.shape[0],1)),self.X_val),axis=1)\n",
    "        self.X_test1 = np.concatenate((np.ones((self.X_test1.shape[0],1)),self.X_test1),axis=1)\n",
    "        self.X_test2 = np.concatenate((np.ones((self.X_test2.shape[0],1)),self.X_test2),axis=1)\n",
    "        n=self.X_train.shape[1]\n",
    "        def cost(data,y,params):\n",
    "            total_cost =0\n",
    "            for i in range(len(data)):\n",
    "                total_cost+=((1/(2*m))* ((data[i]*params).sum() -y[i])**2)\n",
    "            cost_list.append(total_cost)\n",
    "            #print(cost_list)\n",
    "            return total_cost\n",
    "        # gradient descent\n",
    "        def grad_des(data,y,params,alpha,no_of_iterations):\n",
    "            costs_array=[]\n",
    "            for i in range(no_of_iterations):\n",
    "                slopes = np.zeros (n)\n",
    "                for j in range(len(data)):\n",
    "                    for k in range (n):\n",
    "                        slopes[k] += (1/m)*((data[j]*params).sum() -y[j])*data[j][k]\n",
    "                params = params - (alpha*slopes)\n",
    "                costs_array.append(cost(data,y,params))\n",
    "            #costs.append(costs_array[-1])\n",
    "            return [params,costs_array[-1]]\n",
    "        \n",
    "        sizes =[]\n",
    "        params = np.zeros(n)\n",
    "        costs_train=[]\n",
    "        costs_val=[]\n",
    "        costs_test=[]\n",
    "        costs_test2=[]\n",
    "        \n",
    "        for i in range(0,len(self.X_train),100):\n",
    "            params_1=grad_des(self.X_train[0:i],self.y_train[0:i],params,0.1,100)\n",
    "            costs_train.append(params_1[1])\n",
    "            sizes.append(i)\n",
    "            y_predval = np.dot(params_1[0],self.X_val.T)\n",
    "            costs_val.append((mean_squared_error(self.y_val,y_predval)))\n",
    "            y_predtest1 = np.dot(params_1[0],self.X_test1.T)\n",
    "            costs_test.append((mean_squared_error(self.y_test1,y_predtest1)))\n",
    "            y_predtest2 = np.dot(params_1[0],self.X_test2.T)\n",
    "            costs_test2.append((mean_squared_error(self.y_test2,y_predtest2)))\n",
    "\n",
    "        self.RMSE_TEST1['LINEAR REGRESSION'] = self.rmse(y_predtest1,self.y_test1)\n",
    "        self.RMSE_TEST2['LINEAR REGRESSION'] = self.rmse(y_predtest2,self.y_test2)\n",
    "\n",
    "        self.MSE_TEST1['LINEAR REGRESSION'] = mean_squared_error(y_predtest1,self.y_test1)\n",
    "        self.MSE_TEST2['LINEAR REGRESSION'] = mean_squared_error(y_predtest2,self.y_test2)\n",
    "        \n",
    "    def linear_regression_sklearn(self):\n",
    "        model  = LinearRegression().fit(self.X_train,self.y_train)\n",
    "        y_predtest1 = model.predict(self.X_test1)\n",
    "        y_predtest2 = model.predict(self.X_test2)\n",
    " \n",
    "        self.RMSE_TEST1['LINEAR REGRESSION SKLEARN'] = self.rmse(y_predtest1,self.y_test1)\n",
    "        self.RMSE_TEST2['LINEAR REGRESSION SKLEARN'] = self.rmse(y_predtest2,self.y_test2)\n",
    "\n",
    "        self.MSE_TEST1['LINEAR REGRESSION SKLEARN'] = mean_squared_error(y_predtest1,self.y_test1)\n",
    "        self.MSE_TEST2['LINEAR REGRESSION SKLEARN'] = mean_squared_error(y_predtest2,self.y_test2)\n",
    "              \n",
    "    def decision_tree_sklearn(self):\n",
    "        model = DecisionTreeRegressor(min_samples_leaf=5,random_state = 0).fit(self.X_train,self.y_train)\n",
    "        y_predtest1 = model.predict(self.X_test1)\n",
    "        y_predtest2 = model.predict(self.X_test2)\n",
    " \n",
    "        self.RMSE_TEST1['DECISION TREE'] = self.rmse(y_predtest1,self.y_test1)\n",
    "        self.RMSE_TEST2['DECISION TREE'] = self.rmse(y_predtest2,self.y_test2)\n",
    "\n",
    "        self.MSE_TEST1['DECISION TREE'] = mean_squared_error(y_predtest1,self.y_test1)\n",
    "        self.MSE_TEST2['DECISION TREE'] = mean_squared_error(y_predtest2,self.y_test2)\n",
    "         \n",
    "    def random_forest_sklearn(self):\n",
    "        model = RandomForestRegressor(n_estimators =1000,random_state = 42).fit(self.X_train,self.y_train)\n",
    "        y_predtest1 = model.predict(self.X_test1)\n",
    "        y_predtest2 = model.predict(self.X_test2)\n",
    " \n",
    "        self.RMSE_TEST1['RANDOM FOREST'] = self.rmse(y_predtest1,self.y_test1)\n",
    "        self.RMSE_TEST2['RANDOM FOREST'] = self.rmse(y_predtest2,self.y_test2)\n",
    "\n",
    "        self.MSE_TEST1['RANDOM FOREST'] = mean_squared_error(y_predtest1,self.y_test1)\n",
    "        self.MSE_TEST2['RANDOM FOREST'] = mean_squared_error(y_predtest2,self.y_test2)\n",
    "    \n",
    "    def neural_network(self):\n",
    "\n",
    "        # Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "        model.fit(self.X_train, self.y_train,validation_data=(self.X_val,self.y_val), epochs=100, batch_size=12)\n",
    "        y_predtest1=model.predict(self.X_test1)\n",
    "        y_predtest2=model.predict(self.X_test2)\n",
    "\n",
    "        self.RMSE_TEST1['NEURAL NETWORK'] = self.rmse(y_predtest1,self.y_test1)\n",
    "        self.RMSE_TEST2['NEURAL NETWORK'] = self.rmse(y_predtest2,self.y_test2)\n",
    "\n",
    "        self.MSE_TEST1['NEURAL NETWORK'] = mean_squared_error(y_predtest1,self.y_test1)\n",
    "        self.MSE_TEST2['NEURAL NETWORK'] = mean_squared_error(y_predtest2,self.y_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tB3Fvs7dgNd9",
    "outputId": "a9f03001-c2fb-425f-ceda-4d92b6b79474"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dd49c37d4547>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NEURAL NETWORK: Test2\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MSE:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predtest2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RMSE:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predtest2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;31m# pipeline.model(model_type='decision_tree_sklearn')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[0malgos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'decision_tree_sklearn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'random_forest_sklearn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'linear_regression_sklearn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'linear_regression'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neural_network'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "class Classification:\n",
    "\n",
    "    X_train,X_val,X_test1,X_test2 = None,None,None,None\n",
    "    y_train,y_val,y_test1,y_test2 = None,None,None,None\n",
    "\n",
    "    ACC_1 = {'DECISION TREE':None,'LOGISTIC REGRESSION':None,'NAIVE BAYES':None,'NEURAL NETWORK':None}\n",
    "    ACC_2 = {'DECISION TREE':None,'LOGISTIC REGRESSION':None,'NAIVE BAYES':None,'NEURAL NETWORK':None}\n",
    "    \n",
    "    def __init__(self,X_train,y_train,X_val,y_val,X_test1,y_test1,X_test2,y_test2):\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.X_test1 = X_test1\n",
    "        self.X_test2 = X_test2\n",
    "        self.y_train = y_train\n",
    "        self.y_val = y_val\n",
    "        self.y_test1 = y_test1\n",
    "        self.y_test2 = y_test2\n",
    "\n",
    "    def tabulate(self,options=['all']):\n",
    "        E_TEST_lst = []\n",
    "        if(options[0] == 'all'):E_TEST_lst = [self.ACC1,self.ACC2]\n",
    "        else:\n",
    "            ACC_test1 = {}\n",
    "            ACC_test2 = {}\n",
    "\n",
    "        lf = list(filter(lambda x:x in self.RMSE_TEST1.keys,options))\n",
    "        if(len(lf)!=len(options)):\n",
    "            print(\"Invalid Options Present\")\n",
    "            return\n",
    "\n",
    "        for option in options:\n",
    "            ACC_test1[option] = self.ACC_1[option]\n",
    "            ACC_test2[option] = self.ACC_2[option]\n",
    "\n",
    "        E_test_lst = [ACC_test1,ACC_test2]\n",
    "\n",
    "        E_TEST_df = pd.DataFrame(E_TEST_lst,index=['TEST1','TEST2'])\n",
    "        print(E_TEST_df)\n",
    "\n",
    "\n",
    "    def model(self,model_type = 'decision_tree'):\n",
    "        if(model_type == 'all'):\n",
    "            self.logistic_regression_sklearn()\n",
    "            self.decision_tree_sklearn()\n",
    "            self.naive_bayes_sklearn()\n",
    "            self.tabulate(['all'])\n",
    "\n",
    "        elif(model_type == 'logistic_regression'):\n",
    "            self.logistic_regression_sklearn()\n",
    "            self.tabulate(['LOGISTIC REGRESSION'])\n",
    "\n",
    "        elif(model_type == 'decision_tree'):\n",
    "            self.decision_tree_sklearn()\n",
    "            self.tabulate(['DECISION TREE'])\n",
    "\n",
    "        elif(model_type == 'naive_bayes'):\n",
    "            self.naive_bayes_sklearn()\n",
    "            self.tabulate(['NAIVE BAYES'])\n",
    "\n",
    "        elif(model_type == 'neural_network'):\n",
    "            self.neural_network()\n",
    "            self.tabulate(['NEURAL NETWORK'])\n",
    "\n",
    "    def logistic_regression_sklearn(self):\n",
    "        clf = LogisticRegression(random_state=0).fit(self.X_train, self.y_train)\n",
    "        y_predtest1 = clf.predict(self.X_test1)\n",
    "        y_predtest2 = clf.predict(self.X_test2)\n",
    "\n",
    "        self.ACC1['LOGISTIC REGRESSION'] = accuracy_score(y_predtest1,self.y_test1)\n",
    "        self.ACC2['LOGISTIC REGRESSION'] = accuracy_score(y_predtest2,self.y_test2)\n",
    "\n",
    "\n",
    "    def generate_confusion_matrix(self,predictions,true_values):\n",
    "        print(confusion_matrix(predictions,true_values))\n",
    "\n",
    "    \n",
    "    def decision_tree_sklearn(self):\n",
    "        clf = DecisionTreeClassifier(random_state=0).fit(self.X_train,self.y_train)\n",
    "        y_predtest1 = clf.predict(self.X_test1)\n",
    "        y_predtest2 = clf.predict(self.X_test2)\n",
    "\n",
    "        self.ACC1['DECISION TREE'] = accuracy_score(y_predtest1,self.y_test1)\n",
    "        self.ACC2['DECISION TREE'] = accuracy_score(y_predtest2,self.y_test2)\n",
    "\n",
    "\n",
    "    def naive_bayes(self):\n",
    "        gnb = GaussianNB()\n",
    "        gnb.fit(self.X_train, self.y_train)\n",
    "        y_predtest1 = gnb.predict(self.X_test1)\n",
    "        y_predtest2 = gnb.predict(self.X_test2)\n",
    "\n",
    "        self.ACC1['NAIVE BAYES'] = accuracy_score(y_predtest1,self.y_test1)\n",
    "        self.ACC2['NAIVE BAYES'] = accuracy_score(y_predtest2,self.y_test2)\n",
    "\n",
    "    def neural_network(self):\n",
    "\n",
    "        # No of Outputs\n",
    "        outputs = len(set(self.y_train))\n",
    "\n",
    "        # Model Architecture\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(outputs,activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "        model.fit(self.X_train, self.y_train,validation_data=(self.X_val,self.y_val), epochs=100, batch_size=12)\n",
    "\n",
    "        y_predtest1=model.predict(self.X_test1)\n",
    "        y_predtest2=model.predict(self.X_test2)\n",
    "\n",
    "        self.ACC1['NEURAL NETWORK'] = accuracy_score(y_predtest1,self.y_test1)\n",
    "        self.ACC2['NEURAL NETWORK'] = accuracy_score(y_predtest2,self.y_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5tE8t3YgNeB"
   },
   "outputs": [],
   "source": [
    "pre_1 = Preprocess('Test_Dataset_ to_ INTERN.csv')\n",
    "pre_2 = Preprocess('To Intern_New Dataset for testing.csv')\n",
    "\n",
    "X_train,y_train,X_val,y_val = pre_1.preprocess(test_size=0.3)\n",
    "X_test1,y_test1,X_test2,y_test2 = pre_2.preprocess(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvm6xcH6gNeE",
    "outputId": "d1215b29-df7b-48b9-df98-5ff17851385f",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Classification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c7c68a299567>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassification\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Classification' is not defined"
     ]
    }
   ],
   "source": [
    "classification = Classification(X_train,y_train,X_val,y_val,X_test1,y_test1,X_test2,y_test2)\n",
    "regression = Regression(X_train,y_train,X_val,y_val,X_test1,y_test1,X_test2,y_test2)\n",
    "\n",
    "model_type = 'regression'\n",
    "\n",
    "if model_type == 'regression':\n",
    "  # options for model = ['LINEAR REGRESSION','LINEAR REGRESSION SKLEARN','DECISION TREE','RANDOM FOREST','NEURAL NETWORK']\n",
    "  regression.model(model_type='all')\n",
    "else:\n",
    "  # options for model = ['DECISION TREE','LOGISTIC REGRESSION','NAIVE BAYES','NEURAL NETWORK']\n",
    "  classification.model(model_type='all')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Combined_updated.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
